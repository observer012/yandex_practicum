# Защита персональных данных клиентов

<h1>Содержание<span class='tocSkip'></span></h1>

* [1 Загрузка данных](#my_section_1) <a id='content_1'></a>
  * [1.1 Загрузка данных](#my_section_2) <a id='content_2'></a>
  * [1.2 Ознакомление](#my_section_3) <a id='content_3'></a>
    * [1.2.1 Проверка на дубликаты](#my_section_4) <a id='content_4'></a>
    * [1.2.2 Изучение выбросов](#my_section_5) <a id='content_5'></a>
    * [1.2.3 Заключение](#my_section_6) <a id='content_6'></a>
  * [1.3 Предобработка](#my_section_7) <a id='content_7'></a>
  * [1.4 Заключение](#my_section_8) <a id='content_8'></a>
* [2 Умножение матриц](#my_section_9) <a id='content_9'></a>
* [3 Алгоритм преобразования](#my_section_10) <a id='content_10'></a>
* [4 Проверка алгоритма](#my_section_11) <a id='content_11'></a>
* [5 Вывод](#my_section_12) <a id='content_12'></a>


# Описание проекта

**Задача:**
- Нужно защитить данные клиентов. Разработь метод преобразования данных, чтобы по ним было сложно восстановить персональную информацию. Обосновать корректность его работы.
- При преобразовании данных качество моделей машинного обучения ухудшиться не должно.

**План работы:**
1. Загрузка и изучение данных.
2. Изучение вопроса и обоснование решения. 
3. Рассмотрение алгоритма преобразования данных.
4. Создание алгоритма.

**Описание данных:**

Набор данных находится в файле data.csv.
- Признаки: пол, возраст и зарплата застрахованного, количество членов его семьи.
- Целевой признак: количество страховых выплат клиенту за последние 5 лет.

**Форматирование текста:**
- *Курсивом — небольшие выводы*;
- Обычным — дейсвия.

<a id='my_section_1'></a>
## [Загрузка данных](#content_1)

<a id='my_section_2'></a>
### [Загрузка данных](#content_2)

Проведём загрузку необходимых библиотек и модулей


```python
from random import randint
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler
```

Проведём загрузку файла


```python
def download(name):
    path1 = '/datasets/'
    path2 = 'https://..'
    try:
        data = pd.read_csv(name)
    except FileNotFoundError:
        try: 
            data = pd.read_csv(path1 + name)
        except FileNotFoundError:
            data = pd.read_csv(path2 + name)
    except Exception as ex:
        print("Some error:", ex)
    return data    
```


```python
data = download('data.csv')
```

<a id='my_section_3'></a>
### [Ознакомление](#content_3)

**head**

Изучим данные


```python
data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Пол</th>
      <th>Возраст</th>
      <th>Зарплата</th>
      <th>Члены семьи</th>
      <th>Страховые выплаты</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>41.0</td>
      <td>49600.0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>46.0</td>
      <td>38000.0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>29.0</td>
      <td>21000.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>21.0</td>
      <td>41700.0</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>28.0</td>
      <td>26100.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



*Наименования стобцов начинаются в верхнем регитсре и некоторые разделены пробелами. Стоит провести преобразование.*

**Переименование столбцов**

Страхования компания «Хоть потоп» русскоязычная, изменение колонок будет соответствовать.


```python
data.columns
```




    Index(['Пол', 'Возраст', 'Зарплата', 'Члены семьи', 'Страховые выплаты'], dtype='object')




```python
data = data.rename(columns={'Пол':'пол', 'Возраст':'возраст', 'Зарплата':'зарплата',
                            'Члены семьи':'члены_семьи', 'Страховые выплаты':'страховые_выплаты'})
```

**info**


```python
data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 5000 entries, 0 to 4999
    Data columns (total 5 columns):
     #   Column             Non-Null Count  Dtype  
    ---  ------             --------------  -----  
     0   пол                5000 non-null   int64  
     1   возраст            5000 non-null   float64
     2   зарплата           5000 non-null   float64
     3   члены_семьи        5000 non-null   int64  
     4   страховые_выплаты  5000 non-null   int64  
    dtypes: float64(2), int64(3)
    memory usage: 195.4 KB
    

*Пропуски в данных не обнаружены. Целевой признак — категориальный, значит решаем задачу классификации. Типы у столбцов указаны в соответствии с находящимся данными, однако не понятно, почему возрасть имеет тип float64. Изучим содержание столбца.*


```python
data['возраст'].unique()
```




    array([41., 46., 29., 21., 28., 43., 39., 25., 36., 32., 38., 23., 40.,
           34., 26., 42., 27., 33., 47., 30., 19., 31., 22., 20., 24., 18.,
           37., 48., 45., 44., 52., 49., 35., 56., 65., 55., 57., 54., 50.,
           53., 51., 58., 59., 60., 61., 62.])



*Тип данных можно изменить на int64, это займёт меньше памяти.*

<a id='my_section_4'></a>
#### [Проверка на дубликаты](#content_4)

Определим функцию для проверки и удаления дубликатов. Проводить поиск будем по всем стобцам, так как признаков мало и велика вероятность совпадения, кроме того, нет уникальных идентификаторов.


```python
def is_duplucates(data, drop=False):
    print(f'Количество дубликатов обнаружено: {data.duplicated().sum()}')
    if drop == True:
        print(f'Строк/столбцов до удаления дубликатов {data.shape}')
        data = data.drop_duplicates()
        print(f'Строк/столбцов после удаления дубликатов {data.shape}')
        return data
```


```python
is_duplucates(data)
```

    Количество дубликатов обнаружено: 153
    

<a id='my_section_5'></a>
#### [Изучение выбросов](#content_5)

В рамках задачи данный этап не нужен, так как необходимо защитить данные, чтобы при преобразовании качество модели не ухудшилось.


```python
data.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>пол</th>
      <th>возраст</th>
      <th>зарплата</th>
      <th>члены_семьи</th>
      <th>страховые_выплаты</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
      <td>5000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.499000</td>
      <td>30.952800</td>
      <td>39916.360000</td>
      <td>1.194200</td>
      <td>0.148000</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.500049</td>
      <td>8.440807</td>
      <td>9900.083569</td>
      <td>1.091387</td>
      <td>0.463183</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>18.000000</td>
      <td>5300.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>24.000000</td>
      <td>33300.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.000000</td>
      <td>30.000000</td>
      <td>40200.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>37.000000</td>
      <td>46600.000000</td>
      <td>2.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>65.000000</td>
      <td>79000.000000</td>
      <td>6.000000</td>
      <td>5.000000</td>
    </tr>
  </tbody>
</table>
</div>



Средние показатели признаков:
- пол: распределение примерно поровну (от 0 до 1);
- возраст: равен 30 годам (от 18 до 65);
- з.п.: 40000 (от 5300 до 79000);
- кол-во членов семьи: 1 (от 1 до 6);
- страховые выплаты: 0.148 (от 0 до 5).

Определим функцию для построения графиков и определения границ усов. Изучать выбросы будем у трёх столбцов(в силу типа представленной информации и отношению их к количественным признакам):
- возраст;
- зарплата;
- члены_семьи.


```python
def box_moustache(data):
    moustache = {}
    col = {'возраст':'лет', 'зарплата':'у.е.', 'члены_семьи':'человек(a)'}
    fig, ax = plt.subplots(1, 3, figsize=(13,6))
    fig.suptitle('Ящики с усами', fontsize=14, fontweight='bold')
    fig.subplots_adjust(top=.8)

    count = 0
    for key, val in col.items():
        b = ax[count].boxplot(data[key])
        # Выделение крайних усов боксплота
        moustache[key] = [item.get_ydata()[1] for item in b['whiskers']]
        ax[count].grid()
        ax[count].set_title(key)
        ax[count].set_ylabel(val)
        count += 1

    fig.tight_layout()


    return moustache    

```


```python
moustache_data = box_moustache(data)
```


    
![png](img/output_38_0.png)
    


Изучим численные границы


```python
moustache_data
```




    {'возраст': [18.0, 56.0],
     'зарплата': [13400.0, 66300.0],
     'члены_семьи': [0.0, 5.0]}



Определим функцию для ограничения выбранных столбцов по усам


```python
def limit_moustache(data, drop=False):
    data_s = data.shape[0]
    for key, val in moustache_data.items():
        data = data.loc[(data[key] >= val[0]) & (data[key] <= val[1])]
    res = data_s - data.shape[0]
    if drop == False:
        print(f'Обнаружено выбросов: {res}')
    else:
        print(f'Выбросов удалено: {res}')
        return data

```


```python
limit_moustache(data)
```

    Обнаружено выбросов: 56
    

<a id='my_section_6'></a>
#### [Заключение](#content_6)

В данных обнаружено:
- столбец `возраст` имеет тип данных float64, а должен int64;
- 153 дубликата при поиске по всем столбцам;
- 56 выбросов.

**Вывод:**
Необходимо провести предобработку данных и избавиться от помех.

<a id='my_section_7'></a>
### [Предобработка](#content_7)

**Изменение типа данных**


```python
data['возраст'] = data['возраст'].astype('int64')
```

**Избавление от дубликатов**


```python
data = is_duplucates(data, drop=True)
```

    Количество дубликатов обнаружено: 153
    Строк/столбцов до удаления дубликатов (5000, 5)
    Строк/столбцов после удаления дубликатов (4847, 5)
    

**Обработка выбросов**


```python
data = limit_moustache(data, drop=True)
```

    Выбросов удалено: 56
    

<a id='my_section_8'></a>
### [Заключение](#content_8)

Проведено подключение библиотек и модулей, загрузка и ознакомление с данными. Были выявлены помехи, мешающие или усложнающие дальнейшую работу и анализ данных:
- имена столбцов находились в непринятом формате;
- столбец `возраст` имел тип столбца `float64`;
- обнаружено 153 дубликата, если искать по всем столбцам;
- в столбцах: `возраст`, `зарплата`, `члены_семьи` были обнаружено 56 выбросов.

В процессе предобработки было сделано:
- имена столбцов переведены в нижний и 'змеиный' регистр;
- изменён тип столбца `возраст` на `int64`;
- набор данных избавлен от дубликатов;
- столбцы с количественным набором данных избавлены от выбросов.



<a id='my_section_9'></a>
## [Умножение матриц](#content_9)

В этой главе требуется ответить на вопрос и обосновать решение.</br>

**Вопрос:** </br>
Признаки умножают на обратимую матрицу. Изменится ли качество линейной регрессии? (Её можно обучить заново.)</br>

**Варианты ответов:**
- a. Изменится. Приведите примеры матриц.
- b. Не изменится. Укажите, как связаны параметры линейной регрессии в исходной задаче и в преобразованной.

**Ответ:**
b. Не изменится

**Обоснование:**

Используемые свойства:
$$
(AB)^T=B^T A^T
$$
$$
(AB)^{-1} = B^{-1} A^{-1}
$$
$$
A A^{-1} = A^{-1} A = E
$$
$$
AE = EA = A
$$
\
Обозначения:

- $X$ — матрица признаков (нулевой столбец состоит из единиц)

- $y$ — вектор целевого признака

- $P$ — матрица, на которую умножаются признаки

- $w$ — вектор весов линейной регрессии (нулевой элемент равен сдвигу)

Доказательство:
$$
a = Xw = XEw = XPP^{-1}w = (XP)P^{-1}w = (XP)w'
$$
\
Требуется доказать, что предсказания не изменятся, имеем  $a =  Xw$,   $a' = X'w'$
\
\
$$
    w = (X^T X)^{-1} X^T y
$$
\
$$
w' = ((XP)^T XP)^{-1} (XP)^T y
$$
$$
w' = (P^T (X^T X) P)^{-1} (XP)^T y
$$
$$
w' = (P^T (X^T X) P)^{-1} P^T X^T y
$$

$$
w' = (P)^{-1} (X^T X)^{-1} (P^T)^{-1} P^T X^T y
$$
$$
w' = (P)^{-1} (X^T X)^{-1} E X^T y
$$
$$
w' = (P)^{-1} w
$$


**Заключение:** предсказания не изменятся, согласно итогу проведённого преобразования и доказательства.

**Вывод:**
Качество линейной регресии не изменится при умножении матрицы признаков на обратимую матрицу. Значит, что это можно использовать для шифрования персональной информации.

<a id='my_section_10'></a>
## [Алгоритм преобразования](#content_10)

В этом пункте предложим алгоритм преобразования данных, рассчитанный в прошлом пукте. В целом для задачи кодирования данных подойдут и другие операции с матрицей: умножение и деление на число, вектор, формула будет такая же. Подобные операции справделивы и для обратимых матриц.

**Алгоритм**

Был рассмотрен в пункте 2, где происходило умнажение признаков на обратимую матрицу.

**Обоснование**

Также приведено в главе 2.

<a id='my_section_11'></a>
## [Проверка алгоритма](#content_11)

В этой главе необходимо запрограммировать алгоритм, рассмотренный в главе 2, применив матричные операции. Проверим, что качество линейной регрессии из sklearn не отличается до и после преобразования. Применим метрику R2.

Определим функцию для разделения на выборки и масштабирования


```python
def signs_scal(data):
    features = data.drop(['страховые_выплаты'],axis=1)
    target = data['страховые_выплаты']
    numeric = ['возраст', 'зарплата', 'члены_семьи']
    
    scaler = StandardScaler()
    scaler.fit(features[numeric])

    pd.options.mode.chained_assignment = None
    features.loc[:, numeric] = scaler.transform(features.loc[:, numeric])
    return features, target
```

Опеределим функцию создания обратимой матрицы и умножения ее на признаки


```python
def data_maker_p(data):
    count = 0
    while True:
        new_matrix = np.random.normal(randint(1, 10), 1000, size=(data.shape[1],data.shape[1]))
        det = np.linalg.det(new_matrix)
        if det != 0:
            break
        elif det == 0:
            count += 1
            if count == 10:
                print('Вероятно есть ошибка в формуле, детерменант равен 0')
                break
    
    new_data = np.dot(data, new_matrix)
    features_p = pd.DataFrame(new_data, columns = data.columns)
    return features_p  
```

Определим функцию для проверки качества линейной регрессии из sklearn с использованием метрики r2


```python
def Linear_r2_score(features, target):
    model = LinearRegression()
    model.fit(features, target)
    predictions = model.predict(features)
    res = r2_score(target, predictions)
    print(f'Результат вычисления: {res}'
          f'\nОкругление результата: {res :.5}')
    
    return res
```

Проведём разбиение на признаки и масштабирование


```python
features, target = signs_scal(data) 
```

Умножим признаки на обратимую матрицу


```python
features_p = data_maker_p(features)
```

**До преобразования**

Рассчёт качества линейной регресии до преобразования


```python
res_before = Linear_r2_score(features, target)
```

    Результат вычисления: 0.4229314556027187
    Округление результата: 0.42293
    

**После преобразования**

Рассчёт качества линейной регресии после преобразования


```python
res_after = Linear_r2_score(features_p, target)
```

    Результат вычисления: 0.4229314556027187
    Округление результата: 0.42293
    

<a id='my_section_12'></a>
## [Вывод](#content_12)

1. Проведена загрузка и ознакомление с данными, обнаружено:
    - столбец `возраст` имеет тип данных float64, а должен int64;
    - 153 дубликата при поиске по всем столбцам;
    - 56 выбросов.
    
    
2. Проведена предобработка данных, где были исправлены искажения.


3. Проанализирована информации и выбран один из возможных алгоритмов для защиты данных клиентов. Алгоритм основан на шифровании данных путём преобразования исходной информации, умножением признаков на обратимую матрицу во время обучения модели.


4. Проведена проверка алгоритма с использованием метрики r2, где вычеслено значение до преобразования и после, соответственно, значения соответствуют друг друг вплоть до 14 знака:
    - до: 0.4229314556027187 (0.42293)
    - после: 0.42293145560271883 (0.42293)
    
Полученные результаты позволяют заключить, что подобранный алгоритм подходит для защиты данных клиентов.    
